import json
import requests
import base58
import time
import os
from glob import glob

def is_api_working(url, timeout=25, max_retries=4):
    """
    å¢å¼ºç‰ˆAPIæ£€æµ‹ï¼šè§£å†³403è®¿é—®é™åˆ¶é—®é¢˜
    å¢åŠ æ›´å¤šæµè§ˆå™¨æ¨¡æ‹Ÿå¤´ä¿¡æ¯ï¼Œä¼˜åŒ–é‡è¯•ç­–ç•¥
    """
    # è¶…çº§æ¨¡æ‹Ÿæµè§ˆå™¨è¯·æ±‚å¤´ï¼ˆè§£å†³403æ ¸å¿ƒï¼‰
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8",
        "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
        "Accept-Encoding": "gzip, deflate, br",
        "Referer": "https://www.google.com/",  # æ¨¡æ‹Ÿä»è°·æ­Œè·³è½¬
        "Connection": "keep-alive",
        "Upgrade-Insecure-Requests": "1",
        "Sec-Fetch-Dest": "document",
        "Sec-Fetch-Mode": "navigate",
        "Sec-Fetch-Site": "cross-site",
        "Sec-Fetch-User": "?1",
        "Cache-Control": "max-age=0",
        # æ¨¡æ‹Ÿå¸¸è§Cookieï¼ˆéƒ¨åˆ†ç½‘ç«™éœ€è¦åŸºç¡€Cookieæ‰èƒ½è®¿é—®ï¼‰
        "Cookie": "Hm_lvt_123=123456; __cf_bm=abcdefg; _ga=GA1.2.123456789"
    }

    for attempt in range(max_retries):
        try:
            # ç¬¬ä¸€æ¬¡å°è¯•ï¼šå¸¦å®Œæ•´å¤´ä¿¡æ¯çš„GETè¯·æ±‚ï¼ˆç›´æ¥æ¨¡æ‹Ÿæµè§ˆå™¨è¡Œä¸ºï¼‰
            response = requests.get(
                url, 
                timeout=timeout, 
                allow_redirects=True,
                headers=headers,
                verify=False,  # è·³è¿‡SSLéªŒè¯
                stream=True  # ä¸ä¸‹è½½å†…å®¹ï¼Œåªè·å–å“åº”å¤´
            )
            
            # ç‰¹æ®Šå¤„ç†403çŠ¶æ€ç ï¼šå°è¯•æ›´æ¢User-Agentå†è¯•
            if response.status_code == 403:
                print("âš ï¸ æœåŠ¡å™¨è¿”å›403ï¼Œå°è¯•æ›´æ¢æµè§ˆå™¨æ ‡è¯†...")
                headers["User-Agent"] = "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.1 Safari/605.1.15"
                continue  # è¿›å…¥ä¸‹ä¸€æ¬¡é‡è¯•
            
            # 200-399ä¹‹é—´çš„çŠ¶æ€ç è§†ä¸ºæœ‰æ•ˆ
            if 200 <= response.status_code < 400:
                return True
            else:
                print(f"âš ï¸ çŠ¶æ€ç å¼‚å¸¸: {response.status_code}")

        except requests.exceptions.RequestException as e:
            print(f"âš ï¸ ç¬¬{attempt+1}æ¬¡è¯·æ±‚å¤±è´¥: {str(e)}")

        # é‡è¯•é—´éš”é€’å¢ï¼ˆ1sâ†’2sâ†’4sâ†’8sï¼‰
        if attempt < max_retries - 1:
            sleep_time = 2 **attempt
            print(f"â³ ç­‰å¾…{sleep_time}ç§’åé‡è¯•...")
            time.sleep(sleep_time)

    return False

def extract_api_sites(config):
    """
    ä»ä»»æ„JSONç»“æ„ä¸­æå–APIç«™ç‚¹ä¿¡æ¯
    æ”¯æŒå­—å…¸ã€åˆ—è¡¨ç­‰å¤šç§ç»“æ„
    """
    api_sites = {}
    
    # æƒ…å†µ1ï¼šå¦‚æœæ˜¯åˆ—è¡¨ç»“æ„ï¼ˆä½ çš„ouonnkiTV.jsonå±äºè¿™ç§æƒ…å†µï¼‰
    if isinstance(config, list):
        print(f"ğŸ” æ£€æµ‹åˆ°åˆ—è¡¨ç»“æ„ï¼Œå°è¯•ä»ä¸­æå–APIä¿¡æ¯...")
        for idx, item in enumerate(config):
            if isinstance(item, dict):
                # æå–åŒ…å«urlå’Œnameçš„æ¡ç›®ï¼ˆé€‚é…ä½ çš„JSONç»“æ„ï¼‰
                if "url" in item and "name" in item:
                    site_key = f"site_{idx}"  # ç”¨ç´¢å¼•ä½œä¸ºé”®å
                    api_sites[site_key] = {
                        "name": item["name"],
                        "api": item["url"],  # æ˜ å°„ä¸ºç»Ÿä¸€çš„apiå­—æ®µ
                        "id": item.get("id", site_key),
                        "detailUrl": item.get("detailUrl", ""),
                        "isEnabled": item.get("isEnabled", True)
                    }
    
    # æƒ…å†µ2ï¼šå¦‚æœæ˜¯å­—å…¸ç»“æ„ï¼Œä¸”åŒ…å«api_siteå­—æ®µ
    elif isinstance(config, dict):
        if "api_site" in config and isinstance(config["api_site"], dict):
            api_sites = config["api_site"]
        # æƒ…å†µ3ï¼šå¦‚æœæ˜¯å­—å…¸ç»“æ„ï¼Œä½†ç›´æ¥åŒ…å«APIä¿¡æ¯ï¼ˆå¦‚å•ç‹¬çš„APIå¯¹è±¡ï¼‰
        elif "url" in config and "name" in config:
            api_sites["single_site"] = {
                "name": config["name"],
                "api": config["url"],
                "id": config.get("id", "single_site"),
                "detailUrl": config.get("detailUrl", ""),
                "isEnabled": config.get("isEnabled", True)
            }
    
    return api_sites

def process_json_file(input_path, output_dir):
    """å¤„ç†å•ä¸ªJSONæ–‡ä»¶ï¼Œæ”¯æŒåˆ—è¡¨å’Œå­—å…¸ç»“æ„"""
    # è¯»å–æ–‡ä»¶
    with open(input_path, 'r', encoding='utf-8') as f:
        config = json.load(f)
    
    filename = os.path.basename(input_path)
    print(f"\nå¼€å§‹å¤„ç†æ–‡ä»¶: {filename}")
    
    # æå–APIç«™ç‚¹ï¼ˆæ ¸å¿ƒä¿®å¤ï¼šæ”¯æŒåˆ—è¡¨ç»“æ„ï¼‰
    api_sites = extract_api_sites(config)
    
    if not api_sites:
        print(f"âš ï¸ æœªä» {filename} ä¸­æ‰¾åˆ°ä»»ä½•APIç«™ç‚¹ä¿¡æ¯")
    else:
        print(f"å‘ç° {len(api_sites)} ä¸ªAPIç«™ç‚¹ï¼Œå¼€å§‹æ£€æŸ¥...")
    
    # æ£€æŸ¥å¹¶ç­›é€‰å¯ç”¨ç«™ç‚¹
    valid_sites = {}
    for site_key, site_info in api_sites.items():
        api_url = site_info.get('api', '')
        site_name = site_info.get('name', site_key)
        
        # åªæ£€æµ‹åŒ…å«vodæˆ–jsonçš„API
        if "vod" not in api_url.lower() and "json" not in api_url.lower():
            print(f"â„¹ï¸ {site_name} ({api_url}) ä¸åŒ…å«vod/jsonï¼Œç›´æ¥ä¿ç•™")
            valid_sites[site_key] = site_info
            continue
        
        print(f"æ£€æŸ¥ {site_name} ({api_url})...")
        if is_api_working(api_url):
            valid_sites[site_key] = site_info
            print(f"âœ… {site_name} å¯ç”¨")
        else:
            print(f"âŒ {site_name} ä¸å¯ç”¨ï¼Œå·²ç§»é™¤")
    
    # ç”Ÿæˆæ–°é…ç½®ï¼ˆä¿ç•™åŸå§‹ç»“æ„ï¼‰
    new_config = config
    # æ ¹æ®åŸå§‹ç»“æ„ç±»å‹ï¼Œæ’å…¥æœ‰æ•ˆç«™ç‚¹
    if isinstance(config, list):
        # å¯¹äºåˆ—è¡¨ç»“æ„ï¼Œé‡å»ºåˆ—è¡¨åªä¿ç•™æœ‰æ•ˆç«™ç‚¹
        new_config = []
        valid_ids = {site["id"] for site in valid_sites.values()}
        for item in config:
            if isinstance(item, dict) and item.get("id") in valid_ids:
                new_config.append(item)
    elif isinstance(config, dict):
        # å¯¹äºå­—å…¸ç»“æ„ï¼Œæ›¿æ¢api_siteå­—æ®µ
        new_config["api_site"] = valid_sites
    
    # ä¿å­˜ç»“æœ
    os.makedirs(output_dir, exist_ok=True)
    output_path = os.path.join(output_dir, filename)
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(new_config, f, ensure_ascii=False, indent=4)
    
    # ç”Ÿæˆbase58ç¼–ç 
    base58_filename = f"{os.path.splitext(filename)[0]}_base58.txt"
    with open(output_path, 'rb') as f:
        base58_encoded = base58.b58encode(f.read()).decode('utf-8')
    with open(os.path.join(output_dir, base58_filename), 'w', encoding='utf-8') as f:
        f.write(base58_encoded)
    
    print(f"å·²ä¿å­˜å¤„ç†ç»“æœåˆ°: {output_path}")

def main():
    input_dir = 'Initial'
    output_dir = 'output'
    os.makedirs(output_dir, exist_ok=True)
    
    json_files = glob(os.path.join(input_dir, '*.json'))
    if not json_files:
        print(f"è­¦å‘Š: {input_dir} æ–‡ä»¶å¤¹ä¸­æœªæ‰¾åˆ°JSONæ–‡ä»¶")
        return
    
    print(f"å‘ç° {len(json_files)} ä¸ªJSONæ–‡ä»¶ï¼Œå¼€å§‹å¤„ç†...")
    for json_file in json_files:
        process_json_file(json_file, output_dir)
    
    print("\næ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆ!")

if __name__ == "__main__":
    # ç¦ç”¨SSLè­¦å‘Š
    import urllib3
    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
    main()
